<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Yuan Yuan's Homepage</title>
  <link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
  <!--<link rel="shortcut icon" href="../images/fav_icon.png" type="image/x-icon">-->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Bulma Version 0.7.5-->
  <link rel="stylesheet" href="https://unpkg.com/bulma@0.7.5/css/bulma.min.css" />
  <link href='css/style.css?_t=20200916' rel='stylesheet' type='text/css'>
  <script defer src="font-awesome-5.9.0/js/brands.min.js"></script>
  <script defer src="font-awesome-5.9.0/js/fontawesome.min.js"></script>
    <style>
      .red {
        color: #ff0000;
        font-style: normal;
      }
       
      #intro {
       margin-top: 0.2em !important;
      }
      
      .content h3 {
       margin-bottom: 1em!important;
       margin-top: 2.5em!important;
      }

      .content figure {
       width: 90%;
       display: flex;
       align-items: center;
       overflow: hidden;
       margin-left: auto!important;
       margin-right: auto!important;
      }
      
      .columns:not(:last-child) {
       margin-bottom: 1.75rem!important;
      }

      #sidebar {
        width: 80%;
      }

      <!--#sidebar .menu-list a.is-active {-->
      <!--  background-color: #9dd5d8;-->
      <!--}-->

      @media screen and (min-width: 769px), print {
        .column.is-2_5, .column.is-2-tablet {
          flex: none;
          width: 20%;
        }
      }
</style>
    <script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
</head>


<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2_5">
          <div class="sticky">
            <figure class="image" style="width: 10rem;">
              <img class="is-rounded" src="images/psb4.jpg">
            </figure>
            <div class="content">
              <h3 style="margin-top: 1em">Yuan Yuan 袁园</h3>
              <h6>MIT CSAIL</h6>
              <h6>32-G916, 32 Vassar St.</h6>
              <h6>Cambridge, MA 02139</h6>
            </div>
            <!-- details -->
            <div class="details">
              <h3>Email:</h3>
              <p><a href="mailto:miayuan@mit.edu">miayuan[at]mit[dot]edu</a></p>
            </div>
            <!-- social network icons -->
            <div class="social">
              <a href="https://github.com/yyuanad" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
              <a href="https://scholar.google.com/citations?user=9tI89HMAAAAJ" target="_blank">
                <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
              <a href="https://www.linkedin.com/in/yuan-yuan-96451747/" target="_blank">
                <span class="fab fa-linkedin fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
              <a href="https://twitter.com/miayuany" target="_blank">
                <span class="fab fa-twitter fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
            </div>


            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <p class="menu-label"><b>Quick Links</b></p>
              <ul class="menu-list">
                <li><a href="#intro">About Me</a></li>
                <li><a href="#news">News</a></li>
                <li><a href="#publications">Publications</a></li>
                <li><a href="#miscellaneous">Miscellaneous</a></li>
              </ul>
              <div class="column" style="width: 40%">
                <script type='text/javascript' id='clstr_globe' src='//cdn.clustrmaps.com/globe.js?d=VjnfOejvIIrpggl9NSOiRcw0OJHJ0QGzEhq2kCXwP94' async></script>
              </div>
            </div>
          </div>



        </div>
        <div class="column right-panel">
          <div class="content">


            <!--About Me-->
            <h3 id="intro">About Me</h3>
            <p>I am a Postdoctoral Research Associate at <a href="https://www.csail.mit.edu/" target="_blank">Computer Science & Artificial Intelligence Lab</a>
              of <a href="http://www.mit.edu/" target="_blank">Massachusetts Institute of Technology</a>, working with Prof. <a href="http://people.csail.mit.edu/dina/" target="_blank">Dina Katabi</a>.
              Before MIT, I obtained my Ph.D. degree in <a href="https://ece.hkust.edu.hk/" target="_blank">ECE department</a> from <a href="http://www.ust.hk/" target="_blank">Hong Kong University of Science and Technology</a>, advised by Prof. <a href="https://sites.google.com/view/dyyeung" target="_blank">Dit-Yan Yeung</a>.
              I was a visiting research scholar in <a href="https://www.ri.cmu.edu/" target="_blank">The Robotics Institute</a> of <a href="http://www.cmu.edu/" target="_blank">Carnegie Mellon University</a>, working with Prof. <a href="http://www.cs.cmu.edu/~abhinavg/" target="_blank">Abhinav Gupta</a>.

            </p>

            <p>
              My research spans the areas of machine learning, computer vision, and health tech intending to facilitate peoples' more convenient and healthier life. My work covers human action recognition and localization, indoor object detection, people's daily activity summarization, new digital biomarkers and contactless health monitoring of patients with COVID, Parkinson's, etc.
            </p>
            

            <!--News-->
            <h3 id="news">
              News
            </h3>
            <ul>
              <li><span>[04/2022] <a href="https://www.m-psi.fr/Papers/TokenCut2022/" target="_blank">TokenCut</a> is also accepted to L3DIVU workshop, CVPR 2022.</span></li>
              <li><span>[03/2022] Two papers have been accepted to CVPR 2022.</span></li>
	      <li><span>[02/2022] Our paper <a href="https://arxiv.org/pdf/2202.11539.pdf" target="_blank">"Self-Supervised Transformers for Unsupervised Object Discovery using Normalized Cut"</a> is on arXiv.</span></li>    
              <li><span>[11/2021] Our paper <a href="https://arxiv.org/abs/2111.13998.pdf" target="_blank">"Targeted Supervised Contrastive Learning for Long-Tailed Recognition"</a> is on arXiv.</span></li>    
	      <li><span>[10/2021] Attended <a href="https://researchsummit.microsoft.com/" target="_blank">Microsoft Research Summit 2021</a>, virtually.</span></li>
              <li><span>[10/2021] Our paper <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Li_Unsupervised_Learning_for_Human_Sensing_Using_Radio_Signals_WACV_2022_paper.pdf" target="_blank">"Unsupervised Learning for Human Sensing Using Radio Signals"</a> has been accepted to <a href="https://wacv2022.thecvf.com/home" target="_blank">WACV 2022</a>.</span></li> 
              <li><span>[12/2020] Our paper <a href="https://arxiv.org/pdf/2012.09962.pdf" target="_blank">"Addressing Feature Suppression in Unsupervised Visual Representations"</a> is on arXiv.</span></li>
              <li><span>[11/2020] Attended <a href="https://oge.mit.edu/development/pop/" target="_blank">Path of Professorship workshop</a>, MIT, virtually.</span></li>
              <li><span>[09/2020] Our paper "Subgroup-based Rank-1 Lattice Quasi-Monte Carlo" has been accepted to NeurIPS 2020.</span></li>
              <li><span>[08/2020] <b>RF-Diary</b> was covered by:
                <a href="https://techcrunch.com/2020/08/24/mit-wireless-system-can-monitor-what-care-facility-residents-are-doing-while-preserving-privacy/" target="_blank">TechCrunch</a>,
                <a href="https://www.engadget.com/mit-wireless-signals-monitoring-machine-learning-rf-diary-040049578.html" target="_blank">Engadget</a>,
                <a href="https://venturebeat.com/2020/08/24/mit-csails-rf-diary-monitors-people-through-walls-and-in-total-darkness/" target="_blank">VentureBeat</a>,
                <a href="https://www.dailymail.co.uk/sciencetech/article-8665391/AI-device-nursing-homes-monitor-elderly-residents-using-radio-waves.html" target="_blank">DailyMail</a>,
                <a href="https://hothardware.com/news/mit-project-can-track-people-through-walls-and-darkness" target="_blank">Hot Hardware</a>,
		<a href="https://mms.tveyes.com/MediaCenterPlayer.aspx?u=aHR0cDovL21lZGlhY2VudGVyLnR2ZXllcy5jb20vZG93bmxvYWRnYXRld2F5LmFzcHg/VXNlcklEPTMwMzQ3OCZNRElEPTEzNzExMTM5Jk1EU2VlZD0yNTU0JlR5cGU9TWVkaWE%3D" target="_blank">BBC News</a>,
                <a href="https://www.csail.mit.edu/news/device-nursing-homes-can-monitor-residents-activities-permission-and-without-video" target="_blank">MIT CSAIL News</a>, and other media outlets.</span></li>
              <li><span>[07/2020] <a href="http://rf-diary.csail.mit.edu/" target="_blank">RF-Diary</a> has been accepted to ECCV 2020 as oral presentation.</span></li>
              <li><span>[06/2020] <b>RF-ReID</b> was covered by:
                <a href="https://techcrunch.com/2020/06/16/mits-new-way-to-remotely-monitor-vital-signs-over-time-could-help-with-early-covid-19-detection-in-care-homes/" target="_blank">TechCrunch</a>,
                <a href="https://www.yahoo.com/lifestyle/mits-way-remotely-monitor-vital-132517815.html" target="_blank">Yahoo News</a>,
                <a href="https://www.healthcareitnews.com/news/mit-csail-machine-learning-tool-could-help-nursing-homes-predict-covid-19" target="_blank">Healthcare IT News</a>,
                <a href="https://www.csail.mit.edu/news/home-health-device-uses-wireless-signals-identify-person-its-seen" target="_blank">MIT CSAIL News</a>, and other media outlets.</span></li>
              <li><span>[02/2020] <a href="http://rf-reid.csail.mit.edu/" target="_blank">RF-ReID</a> has been accepted to CVPR 2020.</span></li>

            </ul>


            <!--Selected Publications-->
            <h3 id="publications">Selected Publications <span style="font-size: 1rem;margin-left: 1rem;position: relative;bottom: .1rem;"><a href="https://scholar.google.com/citations?user=9tI89HMAAAAJ" target="_blank">[Full List]</a></span></h3>
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2022_tokencut.gif">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Self-Supervised Transformers for Unsupervised Object Discovery using Normalized Cut </b><br>
                    <a href="https://yangtaowang95.github.io/" target="_blank" class="dark">Yangtao Wang</a>, <a href="https://xishen0220.github.io/" target="_blank" class="dark">Xi Shen</a>, <a href="http://hushell.github.io/" target="_blank" class="dark">Xu Hu</a>, <b>Yuan Yuan</b>, <a href="http://crowley-coutaz.fr/jlc/jlc.html" target="_blank" class="dark">James Crowley</a>, <a href="https://research.vaufreydaz.org/" target="_blank" class="dark">Dominique Vaufreydaz</a><br>
                    <i>Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022</i><br>
                    <i>Workshop on Learning with Limited Labelled Data for Image and Video Understanding (<b>CVPR</b>), 2022</i><bi>
                    <a href="https://www.m-psi.fr/Papers/TokenCut2022/" target="_blank">[Project Page]</a>
                    <a href="https://arxiv.org/pdf/2202.11539.pdf" target="_blank">[arXiv]</a>
                    <a href="https://github.com/YangtaoWANG95/TokenCut" target="_blank">[Code (GitHub)]</a>
                    <a href="https://gricad-gitlab.univ-grenoble-alpes.fr/wangyan/tokencut" target="_blank">[Code (GitLab)]</a>
                    <a href='https://colab.research.google.com/github/YangtaoWANG95/TokenCut/blob/master/inference_demo.ipynb'><img alt="Queries" src="https://colab.research.google.com/assets/colab-badge.svg"></a>
		    <a href='https://huggingface.co/spaces/akhaliq/TokenCut'><img alt="Queries" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue"></a>    
                  </p>
                </div>
              </div>
            </article>
		  
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2022_Target_SupCon.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Targeted Supervised Contrastive Learning for Long-Tailed Recognition</b><br>
                    <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <a href="https://scholar.google.com/citations?user=UlaXT00AAAAJ&hl=en" target="_blank" class="dark">Peng Cao*</a>, <b>Yuan Yuan</b>, <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan</a>, <a href="https://www.mit.edu/~yuzhe/" target="_blank" class="dark">Yuzhe Yang</a>, <a href="https://www.rogerioferis.org/" target="_blank" class="dark">Rogerio Feris</a>, Piotr Indyk and Dina Katabi<br>
                    <i>Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022</i><br>
                    <a href="https://arxiv.org/abs/2111.13998.pdf" target="_blank">[arXiv]</a>
                  </p>
                </div>
              </div>
            </article>
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2022_rcl.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Addressing Feature Suppression in Unsupervised Visual Representations</b><br>
                    <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan*</a>, <b>Yuan Yuan</b>, <a href="http://people.csail.mit.edu/hehaodele/" target="_blank" class="dark">Hao He</a>, <a href="https://people.csail.mit.edu/yonglong/" target="_blank" class="dark">Yonglong Tian</a>, <a href="https://www.rogerioferis.org/" target="_blank" class="dark">Rogerio Feris</a>, Piotr Indyk and Dina Katabi<br>
                    <i>arXiv:2012.09962, 2021</i><br>
                    <a href="https://arxiv.org/pdf/2012.09962.pdf" target="_blank">[arXiv]</a>
                    <a href="https://www.youtube.com/watch?v=wbtAOIS16LY" target="_blank">[Talk]</a>
                  </p>
                </div>
              </div>
            </article>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2022_wacv_rfrcl.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Unsupervised Learning for Human Sensing Using Radio Signals</b><br>
                    <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan*</a>, <b>Yuan Yuan*</b> and Dina Katabi<br>
                    <i>Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2022</i><br>
                    <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Li_Unsupervised_Learning_for_Human_Sensing_Using_Radio_Signals_WACV_2022_paper.pdf" target="_blank">[PDF]</a>
                    <a href="papers/poster_2022_wacv_RF_Unsup.pdf" target="_blank">[Poster]</a>
                    <a href="bib/2022_wacv_RF_Unsup.txt" target="_blank">[BibTeX]</a>
                  </p>
                </div>
              </div>
            </article>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2020_neurips_rank_1_lattice.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Subgroup-based Rank-1 Lattice Quasi-Monte Carlo</b><br>
                    <a href="https://yueminglyu.github.io/" target="_blank" class="dark">Yueming Lyu</a>, <b>Yuan Yuan</b> and Ivor W. Tsang<br>
                    <i>Thirty-fourth Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2020</i><br>
                    <a href="https://proceedings.neurips.cc/paper/2020/file/456048afb7253926e1fbb7486e699180-Paper.pdf" target="_blank">[Paper]</a>
                    <a href="https://proceedings.neurips.cc/paper/2020/file/456048afb7253926e1fbb7486e699180-Supplemental.zip" target="_blank">[Supplemental]</a>
                    <a href="https://arxiv.org/pdf/2011.06446.pdf" target="_blank">[arXiv]</a>
                    <a href="papers/poster_2020_neurips_Lattice.pdf" target="_blank">[Poster]</a>
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2020_eccv_rf_diary.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>In-home Daily-Life Captioning Using Radio Signals</b><br>
                    <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan*</a>, <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <b>Yuan Yuan</b> and Dina Katabi<br>
                    <i>European Conference on Computer Vision (<b>ECCV</b>), 2020</i><br>
                    <a href="http://rf-diary.csail.mit.edu/" target="_blank">[Project Page]</a>
                    <a href="http://rf-diary.csail.mit.edu/papers/rfdiary_eccv.pdf" target="_blank">[PDF]</a>
                    <a href="https://arxiv.org/abs/2008.10966" target="_blank">[arXiv]</a>
                    <a href="http://rf-diary.csail.mit.edu/slides/longtalk.pdf" target="_blank">[Slides]</a>
                    <a href="https://www.youtube.com/watch?v=j528nQs4_a8&feature=youtu.be" target="_blank">[Demo]</a>
                    <a href="https://www.youtube.com/watch?v=LA-JW4_ovAQ&feature=youtu.be" target="_blank">[Video]</a>
                    <a href="https://www.youtube.com/watch?v=S2Y-zPJnl9U&feature=youtu.be" target="_blank">[Talk]</a>
                    <a href="https://www.csail.mit.edu/news/device-nursing-homes-can-monitor-residents-activities-permission-and-without-video" target="_blank">[MIT CSAIL News]</a>
                    <a href="http://mms.tveyes.com/MediaCenterPlayer.aspx?u=aHR0cDovL21lZGlhY2VudGVyLnR2ZXllcy5jb20vZG93bmxvYWRnYXRld2F5LmFzcHg/VXNlcklEPTMwMzQ3OCZNRElEPTEzNzExMTM5Jk1EU2VlZD0yNTU0JlR5cGU9TWVkaWE%3D" target="blank">[BBC]</a>
                    <a href="https://techcrunch.com/2020/08/24/mit-wireless-system-can-monitor-what-care-facility-residents-are-doing-while-preserving-privacy/" target="_blank">[TechCrunch]</a>
                    <a href="https://www.engadget.com/mit-wireless-signals-monitoring-machine-learning-rf-diary-040049578.html" target="_blank">[Engadget]</a>
                    <a href="https://venturebeat.com/2020/08/24/mit-csails-rf-diary-monitors-people-through-walls-and-in-total-darkness/" target="_blank">[VentureBeat]</a><br>
                    <em class="red"><b>Oral Presentation (2%)</b></em><br>
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2020_cvpr_rf_reid.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Learning Longterm Representations for Person Re-Identification Using Radio Signals</b><br>
                    <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan*</a>, <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <a href="https://rongyaofang.github.io/" target="_blank" class="dark">Rongyao Fang*</a>, Rumen Hristov, <b>Yuan Yuan</b> and Dina Katabi<br>
                    <i>Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020</i><br>
                    <a href="http://rf-reid.csail.mit.edu/" target="_blank">[Project Page]</a>
                    <a href="http://rf-reid.csail.mit.edu/papers/rfreid_cvpr.pdf" target="_blank">[PDF]</a>
                    <a href="https://arxiv.org/abs/2004.01091" target="_blank">[arXiv]</a>
                    <a href="https://www.youtube.com/watch?v=oYv30obQ8P4&feature=youtu.be" target="_blank">[Video]</a>
                    <a href="https://www.csail.mit.edu/news/home-health-device-uses-wireless-signals-identify-person-its-seen" target="_blank">[MIT CSAIL News]</a>
                    <a href="https://techcrunch.com/2020/06/16/mits-new-way-to-remotely-monitor-vital-signs-over-time-could-help-with-early-covid-19-detection-in-care-homes/" target="_blank">[TechCrunch]</a>
                    <a href="https://www.yahoo.com/lifestyle/mits-way-remotely-monitor-vital-132517815.html" target="_blank">[Yahoo News]</a>
		    <a href="https://www.healthcareitnews.com/news/mit-csail-machine-learning-tool-could-help-nursing-homes-predict-covid-19" target="_blank">[Healthcare IT News]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2019_iclr_maan.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Marginalized Average Attentional Network For Weakly-Supervised Learning</b><br>
                    <b>Yuan Yuan</b>, <a href="https://yueminglyu.github.io/" target="_blank" class="dark">Yueming Lyu</a>, <a href="https://xishen0220.github.io/" target="_blank" class="dark">Xi Shen</a>, Ivor W. Tsang and Dit-Yan Yeung<br>
                    <i>International Conference on Learning Representations (<b>ICLR</b>), 2019</i><br>
                    <a href="https://arxiv.org/pdf/1905.08586.pdf" target="_blank">[PDF]</a>
                    <a href="https://github.com/yyuanad/MAAN" target="_blank">[Code]</a>
		    <a href="bib/2019_iclr_maan.txt" target="_blank">[BibTeX]</a> 
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2019_jmlr_yueming.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Efficient Batch Black-box Optimization with Deterministic Regret Bounds</b><br>
                    <a href="https://yueminglyu.github.io/" target="_blank" class="dark">Yueming Lyu</a>, <b>Yuan Yuan</b> and Ivor W. Tsang<br>
                    <i> Under Review (<b>JMLR</b>), 2019</i><br>
                    <a href="https://arxiv.org/pdf/1905.10041.pdf" target="_blank">[arXiv]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2017_iccv_TD_GraphLSTM.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Temporal Dynamic Graph LSTM for Action-driven Video Object Detection</b><br>
                    <b>Yuan Yuan</b>, Xiaodan Liang, Xiaolong Wang, Dit-Yan Yeung and Abhinav Gupta<br>
                    <i>International Conference on Computer Vision (<b>ICCV</b>), 2017</i><br>
                    <a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Temporal_Dynamic_Graph_ICCV_2017_paper.pdf" target="_blank">[PDF]</a>
                    <a href="https://github.com/xiaolonw/CharadesDet" target="_blank">[Dataset]</a>
                    <a href="bib/2017_iccv_TD_GraphLSTM.txt" target="_blank">[BibTeX]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2016_tcsvt_amin.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Adaptive Block Coding Order for Intra Prediction in HEVC</b><br>
                    Amin Zheng, <b>Yuan Yuan</b>, Jiantao Zhou, Yuanfang Guo, Haitao Yang and Oscar C. Au<br>
                    <i>IEEE Transaction on Circuits and Systems for Video Technology, vol.26, no.11, pp.2152-2158, Nov. (<b>TCSVT</b>), 2016</i><br>
                    <a href="papers/paper_2016_TCSVT_amin.pdf" target="_blank">[PDF]</a><br>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2015_icassp_yuan.jpeg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Image Compression Via Dense Descriptors Assisted Synthesis</b><br>
                    <b>Yuan Yuan</b>, Amin Zheng, Haitao Yang and Oscar C. Au<br>
                    <i>International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2015</i><br>
                    <a href="papers/paper_2015_icassp_yuan.pdf" target="_blank">[PDF]</a><br>
                    <em class="red"><b>Oral Presentation</b></em><br>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2015_icip_amin_mvf.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Motion Vector Fields Based Video Coding</b><br>
                    Amin Zheng, <b>Yuan Yuan</b>, Hong Zhang, Haitao Yang, Pengfei Wan and Oscar C. Au<br>
                    <i>International Conference on Image Processing (<b>ICIP</b>), 2015</i><br>
                    <a href="papers/paper_2015_icip_amin_mvf.pdf" target="_blank">[PDF]</a><br>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2015_icip_amin_of.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Motion Estimation Via Hierarchical Block Matching and Graph Cut</b><br>
                    Amin Zheng, <b>Yuan Yuan</b>, Sunil Prasad Jaiswal and Oscar C. Au<br>
                    <i>International Conference on Image Processing (<b>ICIP</b>), 2015</i><br>
                    <a href="papers/paper_2015_icip_amin_of.pdf" target="_blank">[PDF]</a><br>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2015_icip_yonggen.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Image Colorization Via Color Propagation and Rank Minimization</b><br>
                    Yonggen Ling, Oscar C. Au, Jiahao Pang, Jin Zeng, <b>Yuan Yuan</b> and Amin Zheng<br>
                    <i>International Conference on Image Processing (<b>ICIP</b>), 2015</i><br>
                    <a href="papers/paper_2015_icip_yonggen_colorization.pdf" target="_blank">[PDF]</a><br>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2014_icassp_yuan.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Image Compression Via Sparse Reconstruction</b><br>
                    <b>Yuan Yuan</b>, Oscar C. Au, Amin Zheng and Haitao Yang<br>
                    <i>International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2014</i><br>
                    <a href="papers/paper_2014_icassp_yuan.pdf" target="_blank">[PDF]</a>
                    <a href="papers/poster_2014_icassp_yuan.pdf" target="_blank">[Poster]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2014_icip_haiyan.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Natural Image Matting via Adaptive Local and Nonlocal Sample Clustering</b><br>
                    Haiyan Yang, Oscar C. Au, <b>Yuan Yuan</b> and Wenxiu Sun<br>
                    <i>International Conference on Image Processing (<b>ICIP</b>), 2014</i><br>
                    <a href="papers/paper_2014_icip_haiyan_matting.pdf" target="_blank">[PDF]</a><br>
                    <em class="red"><b>Top 10% Paper Award</b></em><br>
                  </p>
                </div>
              </div>
            </article>


            <h3 >
              Patents and Patent Applications
            </h3>
<!--             <ul>
              <li><a href="https://patents.google.com/patent/CN113160854A/en?oq=CN113160854" target="_blank">Voice interaction system, related method, device and equipment</a>, <a href="https://patentimages.storage.googleapis.com/a4/5a/80/eedd7ce7d28416/CN113160854A.pdf" target="_blank">CN113160854</a>.</li>
              <li><a href="https://patents.google.com/patent/CN112825248A/en?oq=CN112825248" target="_blank">Voice processing method, model training method, interface display method and equipment</a>, <a href="https://patentimages.storage.googleapis.com/a5/6f/ac/6cf253d225b6c8/CN112825248A.pdf" target="_blank">CN112825248</a>.</li>
              <li><a href="https://patents.google.com/patent/CN110096938A/en?oq=CN110096938" target="_blank">Method and device for processing action behaviors in video</a>, <a href="https://patentimages.storage.googleapis.com/03/82/3a/874a0e4d7dd60d/CN110096938A.pdf" target="_blank">CN110096938</a>.</li>
              <li><a href="https://patents.google.com/patent/JP6389264B2/en" target="_blank">Encoding and decoding methods and apparatuses</a>, <a href="https://patentimages.storage.googleapis.com/62/a3/61/0d95dc00cc3003/JP6389264B2.pdf" target="_blank">JP6389264</a>, granted Sep. 2018; <a href="https://patentimages.storage.googleapis.com/48/b8/db/9c9af2352843be/CN104853196B.pdf" target="_blank">CN104853196</a>, granted Oct. 2018; <a href="https://patentimages.storage.googleapis.com/0f/12/3d/4bade0b838d237/KR101960825B1.pdf" target="_blank">KR101960825</a>, granted Mar. 2019;
  <a href="https://patentimages.storage.googleapis.com/21/16/95/6271e1f6b8a679/WO2015124058A1.pdf" target="_blank">WO2015124058</a>, Aug. 2015; <a href="https://patentimages.storage.googleapis.com/f3/54/63/bbc84aebe4e87b/EP3094091A1.pdf" target="_blank">EP3094091A1</a>, Nov. 2016; <a href="https://patentimages.storage.googleapis.com/7b/d4/47/7c2901d8f38217/US20160373767A1.pdf" target="_blank">US20160373767</a>, Dec. 2016.</li>
            </ul> -->
            <ul>
              <li><b>Voice interaction system, related method, device and equipment</b> <a href="https://patents.google.com/patent/CN113160854A/en?oq=CN113160854" target="_blank">[Google Patent Page]</a></li>
              <a href="https://patentimages.storage.googleapis.com/a4/5a/80/eedd7ce7d28416/CN113160854A.pdf" target="_blank">CN113160854</a>, Jan. 2020.
              
              <li><b>Voice processing method, model training method, interface display method and equipment</b> <a href="https://patents.google.com/patent/CN112825248A/en?oq=CN112825248" target="_blank">[Google Patent Page]</a></li>
              <a href="https://patentimages.storage.googleapis.com/a5/6f/ac/6cf253d225b6c8/CN112825248A.pdf" target="_blank">CN112825248</a>, Nov. 2019.

              <li><b>Method and device for processing action behaviors in video</b> <a href="https://patents.google.com/patent/CN110096938A/en?oq=CN110096938" target="_blank">[Google Patent Page]</a></li>
              <a href="https://patentimages.storage.googleapis.com/03/82/3a/874a0e4d7dd60d/CN110096938A.pdf" target="_blank">CN110096938</a>, Jan. 2018.
              
              <li><b>Encoding and decoding methods and apparatuses</b> <a href="https://patents.google.com/patent/US20160373767A1/en" target="_blank">[Google Patent Page]</a></li>
              <a href="https://patentimages.storage.googleapis.com/0f/12/3d/4bade0b838d237/KR101960825B1.pdf" target="_blank">KR101960825</a>, granted Mar. 2019;
              <a href="https://patentimages.storage.googleapis.com/48/b8/db/9c9af2352843be/CN104853196B.pdf" target="_blank">CN104853196</a>, granted Oct. 2018; 
              <a href="https://patentimages.storage.googleapis.com/62/a3/61/0d95dc00cc3003/JP6389264B2.pdf" target="_blank">JP6389264</a>, granted Sep. 2018; 
              <a href="https://patentimages.storage.googleapis.com/7b/d4/47/7c2901d8f38217/US20160373767A1.pdf" target="_blank">US20160373767</a>, Dec. 2016;
              <a href="https://patentimages.storage.googleapis.com/f3/54/63/bbc84aebe4e87b/EP3094091A1.pdf" target="_blank">EP3094091A1</a>, Nov. 2016; 
              <a href="https://patentimages.storage.googleapis.com/21/16/95/6271e1f6b8a679/WO2015124058A1.pdf" target="_blank">WO2015124058</a>, Aug. 2015.  
            </ul>
            
            <h3 id="miscellaneous">
              Selected Honors and Awards
            </h3>
            <ul>
              <li>Ali Star, Alibaba Group, 2019.</li>
              <li>Overseas Research Award for conducting research at Carnegie Mellon University, HKUST, 2016.</li>
              <li>Research Travel Grant, HKUST, 2014, 2015, 2017.</li>
              <li>Meritorious Winner, Mathematical Contest in Modeling of America (MCM), 2011.</li>
              <li>National Scholarship, Ministry of Education of P.R.China, 2009, 2010, 2011.</li>
              <li>Microsoft Young Fellowship, Microsoft Research Asia, 2011.</li>
            </ul>


            <h3 >
              Academic Services
            </h3>
            <ul>
              <li><b>Workshop Committee</b></li>
              PC Member of workshop on Learning with Limited Labelled Data for Image and Video Understanding, CVPR, 2022 <br>
              PC Member of the International Conference on Learning Representations (ICLR) workshop, PAIR^2Struct, 2022 <br>
              PC Member of the IEEE International Conference on Computer Vision (ICCV) workshop, the first workshop on statistic deep learning in computer vision, 2019 <br>
              
              <li><b>Conference Program Committee Member/Reviewer:</b></li>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, 2018, 2019, 2020, 2021, 2022 <br>
              IEEE International Conference on Computer Vision (ICCV), 2017, 2019, 2021 <br>
              International Conference on Machine Learning (ICML), 2021, 2022 <br>
              Neural Information Processing Systems (NeurIPS), 2020, 2021 <br>
              International Conference on Learning Representations (ICLR), 2022 <br>
	      European Conference on Computer Vision (ECCV), 2020, 2022 <br>
              Annual Meeting of the Association for Computational Linguistics (ACL), 2021 <br>
              AAAI Conference on Artificial Intelligence (AAAI), 2019, 2020, 2021 <br>
              Winter Conference on Applications of Computer Vision (WACV), 2022 <br>
              International Joint Conferences on Artificial Intelligence (IJCAI), 2017 <br>

              <li><b>Journal Reviewer</b></li>
              IEEE Transactions on Image Processing (TIP) <br>
              IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) <br>
              IEEE Transactions on Multimedia (TMM) <br>
              IEEE Transactions on Neural Networks and Learning Systems (TNNLS) <br>

            </ul>


            <h3 >
              Teaching
            </h3>
            Duties at various times have included: weekly tutorial classes, weekly computer lab exercises, office hours, mark homework and exam papers.
            <ul>
              <li>TA of ELEC1200 (HKUST) -- A System View of Communications: from Signals to Packets, <i>Spring 2012</i>, <i>Fall 2013</i></li>
              <li>TA of EESM5547 (HKUST) -- Multimedia Signal Processing, <i>Fall 2014</i></li>
            </ul>

            
          </div>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <footer class="container">
      <br><hr>
      <div class="row" style="text-align: center">
        © 2020-2021 Yuan Yuan. Last updated: Mar 23, 2022.
      </div>
    </footer>
  </section>


  <script>

    var $hashList = $('.menu-list a'), offsetList, maxScrollHeight;

    $('#sidebar').on('click', 'a', function(){
      activate($(this))
    });
    
    $(window).on('resize', debounce(calculateBoundary, 300));

    $(document).on('scroll', debounce(judgeScroll, 300));

    calculateBoundary();
    judgeScroll();
    
    function  calculateBoundary() {
      offsetList = $hashList.map(function(idx, ele){
        return $(ele.hash).offset().top
      });
      maxScrollHeight = $(document).height() - $(window).height()
    }
    
    function judgeScroll() {
      var tps = $("html").scrollTop()
              ? $("html").scrollTop()
              : $("body").scrollTop(),
              len = offsetList.length;
      if(tps >= maxScrollHeight-10){
        activate($hashList.eq(len-1));
        return
      }
      for(var i=0; i<len; i++){
       if(tps+50<offsetList[i]){
          activate($hashList.eq(Math.max(0,i-1)));
          return
        }
      }
    }

    function activate(ele){
      $hashList.removeClass('is-active');
      ele.addClass('is-active');
    }

    function debounce(fn, delay) {
      var timeout = null;
      return function () {
        var args = arguments;
        var context = this;
        if (!timeout) {
          timeout = setTimeout(function () {
            timeout = 0;
            return fn.apply(context, args);
          }, delay);
        }
      };
    }



  </script>


</body>

</html>
